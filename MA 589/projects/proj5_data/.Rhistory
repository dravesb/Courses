nrow = 3,
ncol = 200)
f <- forward(Y, logI, logP, logE)
n
n <- length(Y)
Y
ns <- length(logI)
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
s <- Y
f <- matrix(nrow = n, ncol = ns)
f
logI
logE[, s[1]]
s[1]
logE
f[1,] <- logI + logE[,1]
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logE[,1]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[,j]) + logE[j, i]
f
}
#Set variables for this algorithm
logI <- log(c(0, 1, 0))
logP <- matrix(log(c(0.50, 0.50, 0, 0.05, 0.90, 0.05, 0, 0.5, 0.5)),
byrow = TRUE,
nrow = 3)
logE <- matrix(c(dnorm(Y, mean = -1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = 1, sd = .7, log = TRUE)),
nrow = 3,
ncol = 200)
f <- forward(Y, logI, logP, logE)
# soft max (log-sum-exp) of vector `x`
LOGEPS <- log(.Machine$double.eps / 2)
lse <- function (x) {
m <- max(x); x <- x - m
m + log(sum(exp(x[x > LOGEPS])))
}
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logE[,1]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[,j]) + logE[j, i]
f
}
#Set variables for this algorithm
logI <- log(c(0, 1, 0))
logP <- matrix(log(c(0.50, 0.50, 0, 0.05, 0.90, 0.05, 0, 0.5, 0.5)),
byrow = TRUE,
nrow = 3)
logE <- matrix(c(dnorm(Y, mean = -1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = 1, sd = .7, log = TRUE)),
nrow = 3,
ncol = 200)
f <- forward(Y, logI, logP, logE)
f
plot(f[,1])
plot(f[,2])
plot(f[,3])
PYgivenX <- matrix(c(dnorm(Y, mean = -1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = 1, sd = .7, log = TRUE)),
nrow = 3,
ncol = 200)
PYgivenX
PYgivenX <- matrix(c(dnorm(Y, mean = 1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = -1, sd = .7, log = TRUE)),
nrow = 3,
ncol = 200)
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logE[,1]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[,j]) + logE[j, i]
f
}
f <- forward(Y, logI, logP, logE)
f
logP
logP[,1]
ns
f[i - 1,]
i
i = 1
i = 2
f[i-1]
f[i-1,]
logP[j, ]
j = 1
logP[j, ]
ns <- 2 # #states
P <- matrix(c(pf, 1 - pf, 1 - pl, pl), nrow = ns, byrow = T)
E <- matrix(c(.5, .5, pe, 1 - pe), nrow = ns, byrow = T)
logI <- log(c(1, 0)); logP <- log(P); logE <- log(E) # cache logs
logP
P
logPYX
logPYX <- matrix(c(dnorm(Y, mean = -1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = 1, sd = .7, log = TRUE)),
nrow = 200,
ncol = 3) # log[ P( Y_i | X_i = x) ]
logPYX
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logPYX[1,]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[j, ]) + logPYX[i,j]
f
}
f <- forward(Y, logI, logP, logE)
n <- length(s)
s
n
ns <- length(logI)
ns
#Set variables for this algorithm
logI <- log(c(0, 1, 0))
logP <- matrix(log(c(0.50, 0.50, 0, 0.05, 0.90, 0.05, 0, 0.5, 0.5)),
byrow = TRUE,
nrow = 3)
logPYX <- matrix(c(dnorm(Y, mean = -1, sd = .7, log = TRUE),
dnorm(Y, mean = 0, sd = .5, log = TRUE),
dnorm(Y, mean = 1, sd = .7, log = TRUE)),
nrow = 200,
ncol = 3) # log[ P( Y_i | X_i = x) ]
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logPYX[1,]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[j, ]) + logPYX[i,j]
f
}
f <- forward(Y, logI, logP, logE)
f
plot(f[,1])
plot(f[,2])
plot(f[,3])
logPY <- lse(f[200,])
logPY
exp(logPY)
f
logPY
logPYX
Y
plot(Y)
plot(Y, type = "L")
plot(Y, type = "l")
logP
forward <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI)
f <- matrix(nrow = n, ncol = ns)
f[1,] <- logI + logPYX[1,]
for (i in 2:n) # for each position in sequence
for (j in 1:ns) # for each X_i
f[i, j] <- lse(f[i - 1,] + logP[,j]) + logPYX[i,j]
f
}
f <- forward(Y, logI, logP, logE)
f
logPY <- lse(f[200,])
logPy
logPY
library("knitr")
knit2html("file")
cgh <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_datacgh.csv")
Y <- cgh$log_ratio
knit2html("file")
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
m <- matrix(nrow = n, ncol = ns) # maxima
n
m
b <- matrix(nrow = n, ncol = ns) # backtrack pointers
b
m[1,] <- logI + logE[, s[1]]
# recurse
m[1,] <- logI + logPYX[1,]
m[,1]
logPYX[1,]
logI + logPYX[1,]
# recurse
m[1,] <- logI + logPYX[1,]
m
for (i in 2:n) { # for each position in sequence
for (j in 1:ns) { # for each X_i
u <- m[i - 1,] + logP[,j]
m[i, j] <- max(u) + logPYX[i,j]
b[i - 1, j] <- which.max(u)
}
}
# compute most likely assignment of states given data (MAP)
viterbi <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
m <- matrix(nrow = n, ncol = ns) # maxima
b <- matrix(nrow = n, ncol = ns) # backtrack pointers
# recurse
m[1,] <- logI + logPYX[1,]
for (i in 2:n) { # for each position in sequence
for (j in 1:ns) { # for each X_i
u <- m[i - 1,] + logP[,j]
m[i, j] <- max(u) + logPYX[i,j]
b[i - 1, j] <- which.max(u)
}
}
# backtrack
v <- numeric(n)
v[n] <- which.max(m[n,]) # b[n]
for (i in (n - 1):1)
v[i] <- b[i, v[i + 1]]
list(m = m, b = b, seq = v)
}
f <- forward(Y, logI, logP, logPYX)
logPY <- lse(f[200,])
# compute most likely assignment of states given data (MAP)
viterbi <- function (s, logI, logP, logE) {
n <- length(s); ns <- length(logI) # = nrow(logE) = nrow(logP)
m <- matrix(nrow = n, ncol = ns) # maxima
b <- matrix(nrow = n, ncol = ns) # backtrack pointers
# recurse
m[1,] <- logI + logPYX[1,]
for (i in 2:n) { # for each position in sequence
for (j in 1:ns) { # for each X_i
u <- m[i - 1,] + logP[,j]
m[i, j] <- max(u) + logPYX[i,j]
b[i - 1, j] <- which.max(u)
}
}
# backtrack
v <- numeric(n)
v[n] <- which.max(m[n,]) # b[n]
for (i in (n - 1):1)
v[i] <- b[i, v[i + 1]]
list(m = m, b = b, seq = v)
}
viterbi(Y, logI, logP, logPYX)
res <- viterbi(Y, logI, logP, logPYX)
xhat <- apply(res, 1, which.max)
names(res)
xhat <- res$seq
res <- viterbi(Y, logI, logP, logPYX)
xhat <- res$seq
xhat
plot(xhat)
plot(xhat, lty = 2)
plot(xhat, lty = "l")
plot(xhat, type = "l")
names(res)
res$m
res
sum(xhat)
mean(xhat)
plot(Y)
plot(Y)
mu[Xhat]
mu <- c(-1, 0, 1)
mu[Xhat]
mu[xhat]
points(mu[xhat],
type = "l",
lwd = 2)
plot(Y)
mu <- c(-1, 0, 1)
points(mu[xhat],
type = "l",
lwd = 2)
plot(Y)
mu <- c(-1, 0, 1)
points(mu[xhat],
type = "l",
lwd = 2)
res
prob <- res$m[200,]
prob[2]
exp(prob[2])
prob <- res$m[200,]
prob
logit <- function (p) log(p / (1 - p))
inv_logit <- function (x) 1 / (1 + exp(-x))
LOGEPS <- log(.Machine$double.eps / 2)
log1pe <- function (x) {
l <- ifelse(x > 0, x, 0)
x <- ifelse(x > 0, -x, x)
ifelse(x < LOGEPS, l, l + log1p(exp(x)))
}
log_posterior <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
eta <- offset + x * beta
sum(y * eta - log1pe(eta)) - .5 * omega * (beta - beta0) ^ 2
}
step_laplace_mh <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
mu <- inv_logit(offset + x * beta)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2) + omega))
betac <- rnorm(1, beta, s)
muc <- inv_logit(offset + x * betac)
sc <- sqrt(1 / (sum(muc * (1 - muc) * x ^ 2) + omega))
log_R <- log_posterior(betac, y, x, offset, beta0, omega) +
dnorm(beta, betac, sc, log = TRUE) -
(log_posterior(beta, y, x, offset, beta0, omega) +
dnorm(betac, beta, s, log = TRUE))
ifelse(log_R >= 0 || log(runif(1)) < log_R, betac, beta)
}
sample_lpmh <- function (ns, y, x, offset, beta0 = 0, omega = 0,
start = (logit(mean(y)) - offset) / mean(x)) {
beta <- numeric(ns)
beta[1] <- start
for (is in 2:ns)
beta[is] <- step_laplace_mh(beta[is - 1], y, x, offset, beta0, omega)
beta
}
# [ Example ]
# Urn with `W` white balls, `B` = exp(beta) blue balls:
# sample `n` balls, y_i = I(ball is blue)
W <- 90
n <- 100
yc <- 10 # #observed blue balls out of `n` draws
y <- integer(n); y[sample.int(n, yc)] <- 1
x <- rep(1, n)
offset <- -log(W)
# Laplace approximation around mode:
b <- seq(0, 4, length = 100)
plot(b, sapply(b, log_posterior, y, x, offset), type = 'l')
plot(b, sapply(b, log_posterior, y, x, offset), type = 'l')
lmode <- log_posterior(bmode, y, x, offset)
mu <- inv_logit(offset + x * bmode)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2)))
lshift <- -dnorm(bmode, bmode, s, log = TRUE) + lmode
lines(b, dnorm(b, bmode, s, log = TRUE) + lshift, lty = 2)
mcmc_array <- function (ns, nchains, params) {
nparams <- length(params)
array(dim = c(ns, nchains, nparams),
dimnames = list(iterations = NULL,
chains = paste0("chain", 1:nchains),
parameters = params))
}
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2) + omega))
betac <- rnorm(1, beta, s)
muc <- inv_logit(offset + x * betac)
sc <- sqrt(1 / (sum(muc * (1 - muc) * x ^ 2) + omega))
log_R <- log_posterior(betac, y, x, offset, beta0, omega) +
dnorm(beta, betac, sc, log = TRUE) -
(log_posterior(beta, y, x, offset, beta0, omega) +
dnorm(betac, beta, s, log = TRUE))
ifelse(log_R >= 0 || log(runif(1)) < log_R, betac, beta)
step_laplace_mh <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
mu <- inv_logit(offset + x * beta)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2) + omega))
betac <- rnorm(1, beta, s)
muc <- inv_logit(offset + x * betac)
sc <- sqrt(1 / (sum(muc * (1 - muc) * x ^ 2) + omega))
log_R <- log_posterior(betac, y, x, offset, beta0, omega) +
dnorm(beta, betac, sc, log = TRUE) -
(log_posterior(beta, y, x, offset, beta0, omega) +
dnorm(betac, beta, s, log = TRUE))
ifelse(log_R >= 0 || log(runif(1)) < log_R, betac, beta)
}
sample_lpmh <- function (ns, y, x, offset, beta0 = 0, omega = 0,
start = (logit(mean(y)) - offset) / mean(x)) {
beta <- numeric(ns)
beta[1] <- start
for (is in 2:ns)
beta[is] <- step_laplace_mh(beta[is - 1], y, x, offset, beta0, omega)
beta
}
# [ Example ]
# Urn with `W` white balls, `B` = exp(beta) blue balls:
# sample `n` balls, y_i = I(ball is blue)
W <- 90
n <- 100
yc <- 10 # #observed blue balls out of `n` draws
y <- integer(n); y[sample.int(n, yc)] <- 1
x <- rep(1, n)
offset <- -log(W)
# Laplace approximation around mode:
b <- seq(0, 4, length = 100)
plot(b, sapply(b, log_posterior, y, x, offset), type = 'l')
bmode <- logit(mean(y)) - offset
lmode <- log_posterior(bmode, y, x, offset)
mu <- inv_logit(offset + x * bmode)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2)))
lshift <- -dnorm(bmode, bmode, s, log = TRUE) + lmode
lines(b, dnorm(b, bmode, s, log = TRUE) + lshift, lty = 2)
mcmc_array <- function (ns, nchains, params) {
nparams <- length(params)
array(dim = c(ns, nchains, nparams),
dimnames = list(iterations = NULL,
chains = paste0("chain", 1:nchains),
parameters = params))
}
ns <- 1000
nchains <- 4
sims <- mcmc_array(ns, nchains, "beta")
for (ic in 1:nchains)
sims[, ic, ] <- sample_lpmh(ns, y, x, offset)
library(bayesplot)
rhat <- function (sims, ...)
rstan::monitor(sims, print = FALSE, ...)[, "Rhat"]
mcmc_trace(sims)
mcmc_acf(sims)
cgh <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_datacgh.csv")
cgh <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_datacgh.csv")
cgh <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data/cgh.csv")
cgh <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data/cgh.csv")
hla_study <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data/")
hla_snps <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data//hla_snps.csv")
hla_study <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data/hla_study.csv")
hla_snps <- read.csv("~/Documents/Work/github/Courses/MA 589/projects/proj5_data/hla_snps.csv")
for (i in 1:11) {
for (j in 1:11) {
hla_snps[i, paste0("snp", j)] <- ifelse(abs(hla_snps[i, "position"] -
hla_snps[j, "position"]) < 50000, 1, 0)
}
hla_snps[i, i+2] <- 0
}
X <- hla_study[, -1]
Y <- hla_study[, 1]
step_laplace_mh <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
mu <- inv_logit(offset + x * beta)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2) + omega))
betac <- rnorm(1, beta, s)
muc <- inv_logit(offset + x * betac)
sc <- sqrt(1 / (sum(muc * (1 - muc) * x ^ 2) + omega))
log_R <- log_posterior(betac, y, x, offset, beta0, omega) +
dnorm(beta, betac, sc, log = TRUE) -
(log_posterior(beta, y, x, offset, beta0, omega) +
dnorm(betac, beta, s, log = TRUE))
ifelse(log_R >= 0 || log(runif(1)) < log_R, betac, beta)
}
hla_mcmc
X
dim(X)
X
dim(X
)
hla_study
# Laplace approximation around mode:
b <- seq(0, 4, length = 100)
plot(b, sapply(b, log_posterior, y, x, offset), type = 'l')
mcmc_array <- function (ns, nchains, params) {
nparams <- length(params)
array(dim = c(ns, nchains, nparams),
dimnames = list(iterations = NULL,
chains = paste0("chain", 1:nchains),
parameters = params))
}
ns <- 1000
nchains <- 4
sims <- mcmc_array(ns, nchains, "beta")
for (ic in 1:nchains)
sims[, ic, ] <- sample_lpmh(ns, y, x, offset)
library(bayesplot)
rhat <- function (sims, ...)
rstan::monitor(sims, print = FALSE, ...)[, "Rhat"]
mcmc_trace(sims)
mcmc_acf(sims)
rhat(sims)
logit <- function (p) log(p / (1 - p))
inv_logit <- function (x) 1 / (1 + exp(-x))
LOGEPS <- log(.Machine$double.eps / 2)
log1pe <- function (x) {
l <- ifelse(x > 0, x, 0)
x <- ifelse(x > 0, -x, x)
ifelse(x < LOGEPS, l, l + log1p(exp(x)))
}
log_posterior <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
eta <- offset + x * beta
sum(y * eta - log1pe(eta)) - .5 * omega * (beta - beta0) ^ 2
}
step_laplace_mh <- function (beta, y, x, offset, beta0 = 0, omega = 0) {
mu <- inv_logit(offset + x * beta)
s <- sqrt(1 / (sum(mu * (1 - mu) * x ^ 2) + omega))
betac <- rnorm(1, beta, s)
muc <- inv_logit(offset + x * betac)
sc <- sqrt(1 / (sum(muc * (1 - muc) * x ^ 2) + omega))
log_R <- log_posterior(betac, y, x, offset, beta0, omega) +
dnorm(beta, betac, sc, log = TRUE) -
(log_posterior(beta, y, x, offset, beta0, omega) +
dnorm(betac, beta, s, log = TRUE))
ifelse(log_R >= 0 || log(runif(1)) < log_R, betac, beta)
}
1:11
1:11
hla_snps
# Initialize
theta <- matrix(nrow = ncol(X), ncol = ns); theta[, 1] <- 1
beta0 <- numeric(ns); beta0 <- 1
beta <- matrix(nrow = ncol(X), ncol = ns); beta[, 1] <- 1
beta0
beta
X <- hla_study[, -1]
Y <- hla_study[, 1]
X
matrix(nrow = ncol(X), ncol = ns)
# Initialize
theta <- matrix(nrow = ncol(X), ncol = ns); theta[, 1] <- 1
beta <- matrix(nrow = ncol(X), ncol = ns); beta[, 1] <- 1
beta
dim(beta)
theta
dim(theta)
