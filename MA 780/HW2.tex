%%%%% Beginning of preamble %%%%%

\documentclass[12pt]{article}  %What kind of document (article) and what size
\usepackage[document]{ragged2e}

%Packages to load which give you useful commands
\usepackage{graphicx}
\usepackage{amssymb, amsmath, amsthm}
\usepackage{fancyhdr}
\usepackage[linguistics]{forest}
\usepackage{enumerate}
\usepackage[margin=1in]{geometry} 
\pagestyle{fancy}
\fancyhf{}
\lhead{MA 780: HW2, \today}
\rhead{Benjamin Draves}

\renewcommand{\headrulewidth}{.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\topmargin = -0.4 in
%\headheight = 0.0 in t
%\headsep = .3 in
\parskip = 0.2in
%\parindent = 0.0in

%%%%%%%%%%new commands%%%%%%%%%%%%
\newcommand{\N}{{\mathbb{N}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\Q}{{\mathbb{Q}}}
\newcommand{\e}{{\epsilon}}
\newcommand{\del}{{\delta}}
\newcommand{\m}{{\mid}}
\newcommand{\nsum}{{\sum_{i=1}^n}}
\newcommand{\la}{{\langle}}
\newcommand{\ra}{{\rangle}}
\newcommand{\E}{{\mathbb{E}}}
\newcommand{\V}{{\text{Var}}}
\newcommand{\prob}{{\mathbb{P}}}
\newcommand{\ind}{{\mathbf{1}}}
%defines a few theorem-type environments
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{lemma}[theorem]{Lemma}
%%%%% End of preamble %%%%%

\begin{document}
\begin{enumerate}
\item 
	\begin{enumerate}
		\item Let $\{X_n, n\geq 1\}$ and $\{Y_n, n\geq 1\}$ be convergent equivalent sequences of random variables. Then by definition of convergence equivalence this means $$\sum_{n=1}^{\infty}\prob(X_n \neq Y_n)<\infty$$ Note, however, this is exactly the hypothesis of the first Borel-Cantelli Lemma. Hence, using the lemma, we see that convergence equivalence implies $\prob(X_n \neq Y_n,\hspace{.1em} i.o.) = 0$
		\item From part $(a)$ we see that almost everywhere $X_n$ and $Y_n$ only differ for a finite number of terms. That is, there exists an $n_0$ such that for all $n\geq n_0$,  $X_n \overset{a.s.}{=} Y_n$. Using this we can write $$\sum_{n=1}^{\infty}(X_n - Y_n) \overset{a.s.}{=}\sum_{n=1}^{n_0}(X_n - Y_n)<\infty$$ Hence, we see that $\sum_{n=1}^{\infty}(X_n - Y_n)$ converges almost surely. 
		\item Using the same argument as in $(b)$ we see that $$\sum_{n=1}^{\infty}\frac{(X_n-Y_n)}{b_n} \overset{a.s}{=}\sum_{n=1}^{n_0}\frac{(X_n-Y_n)}{b_n}<\infty$$ That is $\sum_{n=1}^{\infty}\frac{(X_n-Y_n)}{b_n}$ converges almost surely. Now, seeing that $b_n\nearrow\infty$, we can use to the Random Kronecker Lemma to conclude $$\frac{1}{b_n}\sum_{k = 1}^{n}(X_k - Y_k)\overset{a.s.}{\longrightarrow} 0\hspace{1em}\text{as}\hspace{1em}n\to\infty$$

	\end{enumerate}	
\item Define $Y_n = X_n\ind_{\{|X_n|\leq A\}}$ for some $A\geq 0$. Recall that convergence of $\sum_{n=1}^{\infty}X_n$ is characterized by the Three-Series Theorem. 


First assume that $\{Y_n, n\geq 1\}$ and $\{X_n, n\geq 1\}$ are convergent equivalent. If $\sum_{n = 1}^{\infty}\V(Y_n) = \infty$, then by the Kolmogorov Three-Series Theorem, with probability 1 $\sum_{n=1}^{\infty}Y_n$ diverges. By convergence equivalence, $\sum_{n=1}^{\infty}X_n$ diverges with probability one. If $\sum_{n=1}^{\infty}\V(Y_n)<\infty$ then by the Kolmorgorov convergence criterion for uniformly bounded random variables $\sum_{n=1}^{\infty}(Y_n -\E(Y_n))$ converges almost surely. Moreover, if $\sum_{n=1}^{\infty}\E(Y_n)$ converges, then $\sum_{n=1}^{\infty}Y_n$ converges almost surely with probability $1$ so by convergence equivalence $\sum_{n=1}^{\infty}X_n$ converge almost surely with probability 1. On the other hand, if $\sum_{n=1}^{\infty}\E(Y_n)$ diverges, then by the Kolmorgov Three-Series Theorem $\sum_{n=1}^{\infty}X_n$ diverges.

Now suppose that $\{X_n, n\geq 1\}$ and $\{Y_n, n\geq 1\}$ are not convergent equivalent. By definition, this implies that $\sum_{n=1}^{\infty}\prob(X_n>A) = \infty$. By the Borel-Cantelli lemma, this implies that $\prob(X_n>A,\hspace{.1em}i.o) = 1$. That is for each $n$ there exists $m>n$ such that $X_m(\omega)>A$ for almost every $\omega\in\Omega$. This implies that $X_n\not\overset{a.s.}{\longrightarrow}0$. Seeing this is a necessary condition for convergence of a random series, necessarily we have $\prob\left[\sum_{n=1}^{\infty}X_n = \infty\right] = 1$. 

Notice that $\prob\left[\sum_{n=1}^{\infty}X_n<\infty\right] = 1$ \textit{only when the hypotheses in Kolomorogov Three-Series Theorem were satisfied}. If any are violated $\prob\left[\sum_{n=1}^{\infty}X_n<\infty\right] = 0$. This matches our intuition as the Three-Series Theorem is a characterization of convergence of the random series. 


\item $(\Longrightarrow)$First suppose that $\sum_{n=1}^{\infty}X_n$ converges almost surely. That is, for all $\e>0$ and $S_n = \sum_{k=1}^nX_k$ we have $\prob(\lim_{n,m\to\infty}|S_n - S_m|\geq\e) = 0$. Now notice, that this implies $\prob(\lim_{n\to\infty}\sup_{m>n}|S_n - S_m|\geq \e) = 0$. Writing this statement in terms of sets, we have $$\prob\left[\bigcap_{m=1}^{\infty}\bigcup_{n=m}^{\infty}\{|S_n-S|\geq \e\}\right] =  \lim_{m\to\infty}\prob\left[\bigcup_{n=m}^{\infty}\{|S_n-S|\geq \e\}\right]$$ Hence, we see that for any $n>m$ we have $$\bigcup_{n=m}^{\infty}\{|S_n-S_m|\geq \e\}\supseteq \{|S_m-S_n|\geq \e\}$$ From here we conclude that $$\lim_{m\to\infty}\lim_{n\to\infty}\prob[|S_m-S_n|\geq \e]\leq\lim_{m\to\infty}\prob\left[\bigcup_{n=m}^{\infty}\{|S_n-S|\geq \e\}\right] = 0$$ Hence $\{S_n\}_{n=1}^{\infty}$ is Cauchy in probability. This shows that $\sum_{n=1}^{\infty}X_n$ converges in probability.


$(\Longleftarrow)$ Now suppose that $\sum_{n=1}^{\infty}X_n$ converges in probability. By Ottavianiâ€™s inequality, for $n,m\in\N$ with $m>n$, we can write $$\max_{n\leq k\leq m}\prob[|S_n - S_k|\geq \e]\geq \frac{1}{3}\prob[\max_{n\leq k \leq m}|S_n - S_k|\geq 3\e]$$ Letting $m\to\infty$ we have 
$$\max_{n\leq k}\prob[|S_n - S_k|\geq \e]\geq \frac{1}{3}\prob[\max_{n\leq k}|S_n - S_k|\geq 3\e]$$ Rewriting in terms of sets, we see that we have $$\sup_{n\leq k}\prob[|S_n - S_k|\geq \e]\geq \frac{1}{3}\prob[\bigcup_{k = n}^{\infty}\{|S_n - S_k|\geq 3\e\}]$$ Now letting $n\to\infty$ we can write the above inequality as $$\lim_{n\to\infty}\sup_{k\geq n}\prob[|S_n - S_k|\geq \e]\geq \frac{1}{3}\lim_{n\to\infty}\prob[\bigcup_{k = n}^{\infty}\{|S_n - S_k|\geq 3\e\}]$$
Now, notice that the left hand side of the inequality is just a characterization of convergence in probability and the right hand side is just a characterization of almost sure convergence. Therefore by assumption $$0 = \lim_{n\to\infty}\sup_{k\geq n}\prob[|S_n - S_k|\geq \e]\geq \frac{1}{3}\lim_{n\to\infty}\prob[\bigcup_{k = n}^{\infty}\{|S_n - S_k|\geq 3\e\}]$$ This shows that  $\{S_n\}_{n=1}^{\infty}$ is almost surely Cauchy. That is $\sum_{n=1}^{\infty}X_n$ convergences almost surely. 



\end{enumerate}	
\end{document} 


